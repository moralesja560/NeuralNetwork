import tensorflow as tf
import numpy as np
import os
import sys


#This function sets the absolute path for the app to access its resources
def resource_path(relative_path):
    """ Get absolute path to resource, works for dev and for PyInstaller """
    base_path = getattr(sys, '_MEIPASS', os.path.dirname(os.path.abspath(__file__)))
    return os.path.join(base_path, relative_path)


X = np.array([-100,-99.6,-99.2,-98.8,-98.4,-98,-97.6,-97.2,-96.8,-96.399,-95.999,-95.599,-95.199,-94.799,-94.399,-93.999,-93.599,-93.199,-92.799,-92.399,-91.999,-91.599,-91.199,-90.799,-90.399,-89.999,-89.599,-89.199,-88.799,-88.399,-87.999,-87.599,-87.199,-86.799,-86.399,-85.999,-85.599,-85.199,-84.799,-84.399,-83.999,-83.599,-83.199,-82.799,-82.399,-81.999,-81.599,-81.199,-80.799,-80.399,-79.999,-79.599,-79.199,-78.799,-78.399,-77.999,-77.599,-77.199,-76.799,-76.399,-75.999,-75.599,-75.199,-74.799,-74.399,-73.999,-73.599,-73.199,-72.799,-72.399,-71.999,-71.599,-71.199,-70.799,-70.399,-69.999,-69.599,-69.199,-68.799,-68.399,-67.999,-67.599,-67.199,-66.799,-66.399,-65.999,-65.599,-65.199,-64.799,-64.399,-63.999,-63.599,-63.199,-62.799,-62.399,-61.999,-61.599,-61.199,-60.799,-60.399,-59.999,-59.599,-59.199,-58.799,-58.399,-57.999,-57.599,-57.199,-56.799,-56.399,-55.999,-55.599,-55.199,-54.799,-54.399,-53.999,-53.599,-53.199,-52.799,-52.399,-51.999,-51.599,-51.199,-50.799,-50.399,-49.999,-49.599,-49.199,-48.799,-48.399,-47.999,-47.599,-47.199,-46.799,-46.399,-45.999,-45.599,-45.199,-44.799,-44.399,-43.999,-43.599,-43.199,-42.799,-42.399,-41.999,-41.599,-41.199,-40.799,-40.399,-39.999,-39.599,-39.199,-38.799,-38.399,-37.999,-37.599,-37.199,-36.799,-36.399,-35.999,-35.599,-35.199,-34.799,-34.399,-33.999,-33.599,-33.199,-32.799,-32.399,-31.999,-31.599,-31.199,-30.799,-30.399,-29.999,-29.599,-29.199,-28.799,-28.399,-27.999,-27.599,-27.199,-26.799,-26.399,-25.999,-25.599,-25.199,-24.799,-24.399,-23.999,-23.599,-23.199,-22.799,-22.399,-21.999,-21.599,-21.199,-20.799,-20.399,-19.999,-19.599,-19.199,-18.799,-18.399,-17.999,-17.599,-17.199,-16.799,-16.399,-15.999,-15.599,-15.199,-14.799,-14.399,-13.999,-13.599,-13.199,-12.799,-12.399,-11.999,-11.599,-11.199,-10.799,-10.399,-9.9999,-9.5999,-9.1999,-8.7999,-8.3999,-7.9999,-7.5999,-7.1999,-6.7999,-6.3999,-5.9999,-5.5999,-5.1999,-4.7999,-4.3999,-3.9999,-3.5999,-3.1999,-2.7999,-2.3999,-1.9999,-1.5999,-1.1999,-0.7999,-0.3999,3.45390,0.40000,0.80000,1.20000,1.60000,2.00000,2.40000,2.80000,3.20000,3.60000,4.00000,4.40000,4.80000,5.20000,5.60000,6.00000,6.40000,6.80000,7.20000,7.60000,8.00000,8.40000,8.80000,9.20000,9.60000,10.0000,10.4000,10.8000,11.2000,11.6000,12.0000,12.4000,12.8000,13.2000,13.6000,14.0000,14.4000,14.8000,15.2000,15.6000,16.0000,16.4000,16.8000,17.2000,17.6000,18.0000,18.4000,18.8000,19.2000,19.6000,20.0000,20.4000,20.8000,21.2000,21.6000,22.0000,22.4000,22.8000,23.2000,23.6000,24.0000,24.4000,24.8000,25.2000,25.6000,26.0000,26.4000,26.8000,27.2000,27.6000,28.0000,28.4000,28.8000,29.2000,29.6000,30.0000,30.4000,30.8000,31.2000,31.6000,32.0000,32.4000,32.8000,33.2000,33.6000,34.0000,34.4000,34.8000,35.2000,35.6000,36.0000,36.4000,36.8000,37.2000,37.6000,38.0000,38.4000,38.8000,39.2000,39.6000,40.0000,40.4000,40.8000,41.2000,41.6000,42.0000,42.4000,42.8000,43.2000,43.6000,44.0000,44.4000,44.8000,45.2000,45.6000,46.0000,46.4000,46.8000,47.2000,47.6000,48.0000,48.4000,48.8000,49.2000,49.6000,50.0000,50.4000,50.8000,51.2000,51.6000,52.0000,52.4000,52.8000,53.2000,53.6000,54.0000,54.4000,54.8000,55.2000,55.6000,56.0000,56.4000,56.8000,57.2000,57.6000,58.0000,58.4000,58.8000,59.2000,59.6000,60.0000,60.4000,60.8000,61.2000,61.6000,62.0000,62.4000,62.8000,63.2000,63.6000,64.0000,64.4000,64.8000,65.2000,65.6000,66.0000,66.4000,66.8000,67.2000,67.6000,68.0000,68.4000,68.8000,69.2000,69.6000,70.0000,70.4000,70.8000,71.2000,71.6000,72.0000,72.4000,72.8000,73.2000,73.6000,74.0000,74.4000,74.8000,75.2000,75.6000,76.0000,76.4000,76.8000,77.2000,77.6000,78.0000,78.4000,78.8000,79.2000,79.6000,80.0000,80.4000,80.8000,81.2000,81.6000,82.0000,82.4000,82.8000,83.2000,83.6000,84.0000,84.4000,84.8000,85.2000,85.6000,86.0000,86.4000,86.8000,87.2000,87.6000,88.0000,88.4000,88.8000,89.2000,89.6000,90.0000,90.4000,90.8000,91.2000,91.6000,92.0000,92.4000,92.8000,93.2000,93.6000,94.0000,94.4000,94.8000,95.2000,95.6000,96.0000,96.4000,96.8000,97.2000,97.6000,98.0000,98.4000,98.8000,99.2000,99.6000,100.000])
y = np.array([0.50636,0.80219,0.97137,0.98720,0.84716,0.57338,0.20907,-0.1882,-0.5558,-0.8356,-0.9835,-0.9762,-0.8147,-0.5245,-0.1516,0.24525,0.60341,0.86631,0.99244,0.96188,0.77946,0.47398,9.36755,-0.3014,-0.6489,-0.8939,-0.9979,-0.9442,-0.7415,-0.4217,-3.5398,0.35657,0.69224,0.91862,0.99998,0.92345,0.70114,0.36813,-2.2999,-0.4104,-0.7331,-0.9401,-0.9986,-0.8994,-0.6583,-0.3132,8.13191,0.46302,0.77163,0.95841,0.99388,0.87244,0.61326,0.25725,-0.1393,-0.5139,-0.8074,-0.9734,-0.9857,-0.8424,-0.5661,-0.2004,0.19692,0.56317,0.84050,0.98514,0.97424,0.80954,0.51702,0.14287,-0.2538,-0.6104,-0.8707,-0.9934,-0.9594,-0.7738,-0.4661,-8.4859,0.30985,0.65564,0.89792,0.99844,0.94133,0.73560,0.41373,2.65511,-0.3648,-0.6986,-0.9220,-0.9999,-0.9200,-0.6948,-0.3598,3.18476,0.41855,0.73918,0.94310,0.99813,0.89558,0.65163,0.30481,-9.0137,-0.4708,-0.7772,-0.9609,-0.9928,-0.8680,-0.6062,-0.2486,0.14812,0.52155,0.81263,0.97543,0.98422,0.83762,0.55878,0.19173,-0.2055,-0.5704,-0.8452,-0.9866,-0.9722,-0.8043,-0.5094,-0.1341,0.26237,0.61743,0.87502,0.99445,0.95689,0.76825,0.45832,7.60367,-0.3182,-0.6623,-0.9017,-0.9989,-0.9383,-0.7295,-0.4056,-1.7701,0.37305,0.70491,0.92547,0.99993,0.91652,0.68841,0.35161,-4.0693,-0.4265,-0.7451,-0.9460,-0.9975,-0.8916,-0.6448,-0.2963,9.89496,0.47864,0.78277,0.96332,0.99177,0.86365,0.59918,0.24011,-0.1568,-0.5290,-0.8177,-0.9773,-0.9826,-0.8327,-0.5514,-0.1830,0.21425,0.57771,0.84996,0.98803,0.97010,0.79902,0.50178,0.12533,-0.2709,-0.6243,-0.8792,-0.9953,-0.9542,-0.7625,-0.4504,-6.7208,0.32663,0.66890,0.90557,0.99927,0.93520,0.72349,0.39755,8.85130,-0.3812,-0.7111,-0.9287,-0.9997,-0.9129,-0.6819,-0.3433,4.95356,0.43456,0.75098,0.94884,0.99690,0.88756,0.63810,0.28790,-0.1077,-0.4863,-0.7882,-0.9656,-0.9906,-0.8591,-0.5920,-0.2315,0.16560,0.53657,0.82282,0.97917,0.98093,0.82782,0.54402,0.17432,-0.2228,-0.5849,-0.8545,-0.9893,-0.9679,-0.7936,-0.4941,-0.1165,0.27941,0.63126,0.88345,0.99616,0.95160,0.75680,0.44252,5.83741,-0.3349,-0.6754,-0.9092,-0.9995,-0.9320,-0.7173,-0.3894,3.45390,0.38941,0.71735,0.93203,0.99957,0.90929,0.67546,0.33498,-5.8374,-0.4425,-0.7568,-0.9516,-0.9961,-0.8834,-0.6312,-0.2794,0.11654,0.49411,0.79366,0.96791,0.98935,0.85459,0.58491,0.22288,-0.1743,-0.5440,-0.8278,-0.9809,-0.9791,-0.8228,-0.5365,-0.1656,0.23150,0.59207,0.85916,0.99060,0.96565,0.78825,0.48639,0.10775,-0.2879,-0.6381,-0.8875,-0.9969,-0.9488,-0.7509,-0.4345,-4.9535,0.34331,0.68196,0.91294,0.99979,0.92879,0.71116,0.38125,-8.8513,-0.3975,-0.7234,-0.9352,-0.9992,-0.9055,-0.6689,-0.3266,6.72080,0.45044,0.76255,0.95428,0.99535,0.87927,0.62437,0.27090,-0.1253,-0.5017,-0.7990,-0.9701,-0.9880,-0.8499,-0.5777,-0.2142,0.18303,0.55142,0.83275,0.98261,0.97734,0.81776,0.52908,0.15686,-0.2401,-0.5991,-0.8636,-0.9917,-0.9633,-0.7827,-0.4786,-9.8949,0.29636,0.64489,0.89160,0.99755,0.94601,0.74511,0.42657,4.06932,-0.3516,-0.6884,-0.9165,-0.9999,-0.9254,-0.7049,-0.3730,1.77019,0.40566,0.72957,0.93830,0.99890,0.90178,0.66230,0.31825,-7.6036,-0.4583,-0.7682,-0.9568,-0.9944,-0.8750,-0.6174,-0.2623,0.13411,0.50942,0.80431,0.97221,0.98662,0.84527,0.57046,0.20559,-0.1917,-0.5587,-0.8376,-0.9842,-0.9754,-0.8126,-0.5215,-0.1481,0.24869,0.60624,0.86808,0.99287,0.96090,0.77723,0.47085,9.01379,-0.3048,-0.6516,-0.8955,-0.9981,-0.9431,-0.7391,-0.4185,-3.1847,0.35988,0.69480,0.92002,0.99999,0.92208,0.69860,0.36482,-2.6551,-0.4137,-0.7356,-0.9413,-0.9984,-0.8979,-0.6556,-0.3098,8.48594,0.46617,0.77389,0.95942,0.99349,0.87070,0.61045,0.25382,-0.1428,-0.5170,-0.8095,-0.9742,-0.9851,-0.8405,-0.5631,-0.1969,0.20040,0.56610,0.84242,0.98575,0.97344,0.80744,0.51397,0.13936,-0.2572,-0.6132,-0.8724,-0.9938,-0.9584,-0.7716,-0.4630,-8.1319,0.31322,0.65832,0.89948,0.99863,0.94012,0.73319,0.41049,2.29996,-0.3681,-0.7011,-0.9234,-0.9999,-0.9186,-0.6922,-0.3565,3.53983,0.42177,0.74156,0.94428,0.99791,0.89399,0.64893,0.30142,-9.3675,-0.4739,-0.7794,-0.9618,-0.9924,-0.8663,-0.6034,-0.2452,0.15163,0.52457,0.81470,0.97620,0.98358,0.83568,0.55583,0.18824,-0.2090,-0.5733,-0.8471,-0.9872,-0.9713,-0.8021,-0.5063])

X = tf.constant(X)
y = tf.constant(y)

#Step 1.- Create a model using the Sequential API
model = tf.keras.Sequential()

model.add(tf.keras.layers.Dense(50, activation ="relu"))
#model.add(tf.keras.layers.Dense(50, activation ="relu"))
model.add(tf.keras.layers.Dense(1))

# Step 2 .- Compile the model
#we can add as much layers as we want
model.compile(loss = tf.keras.losses.mae,
              optimizer = tf.keras.optimizers.Adam(learning_rate= 0.01),
              metrics = ["mae"]
              )
#fit the model
model.fit(tf.expand_dims(X, axis=-1),y, epochs=200)


#model.save(resource_path(r"savedmodel2"))

#predict data
print(model.predict(np.array([-100.0])))